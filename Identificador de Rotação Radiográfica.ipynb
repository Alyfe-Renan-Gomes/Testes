{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa47a03",
   "metadata": {},
   "source": [
    "# Bibliotecas que e funções que serão utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a70dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import os\n",
    "import gc\n",
    "import pathlib\n",
    "import glob\n",
    "import PIL\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import PIL as p\n",
    "import random\n",
    "#=====================================================================================================================#\n",
    "from PIL import Image\n",
    "#=====================================================================================================================#\n",
    "%matplotlib inline\n",
    "#=====================================================================================================================#\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#=====================================================================================================================#\n",
    "from sklearn.model_selection import StratifiedKFold , KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76010af2",
   "metadata": {},
   "source": [
    "# Separando as imagens do banco em duas categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb4bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotaciona(image,img_size):\n",
    "    \n",
    "    angulos=[90,180,-90]     #Ângulos comuns de rotação que podem aparecer\n",
    "    random.shuffle(angulos)  #Torna aleatório a escolha do 1º ângulo. Este passo será importante para os códigos seguintes\n",
    "             \n",
    "    im2 = Image.open(image).convert('L')\n",
    "    im2 = im2.resize((img_size,img_size))\n",
    "    \n",
    "    #Rotacionando a imagem com um dos ângulos dados. A escolha é do ângulo é aleatória\n",
    "    im2=im2.rotate(angulos[0], PIL.Image.NEAREST, expand = 1)        \n",
    "    \n",
    "    return im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0de40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'C:\\\\Users\\\\Alyfe Renan Gomes\\\\Programação\\\\Código da IC'\n",
    "\n",
    "imagens_banco = list(filter(lambda x: True if x.endswith('png') else False,os.listdir(img_path)))\n",
    "\n",
    "random.shuffle(imagens_banco)\n",
    "\n",
    "Rotaciona = imagens_banco[:int((len(imagens_banco)+1)*.5)]\n",
    "Nao_Rotaciona = imagens_banco[int((len(imagens_banco)+1)*.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feccb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 180\n",
    "\n",
    "#Guardando as imagens rotacionadas\n",
    "for index, image in enumerate(Rotaciona):\n",
    "    identificador=image[7:13]\n",
    "    rotaciona_path= f'C:\\\\Users\\\\Alyfe Renan Gomes\\\\Programação\\\\Código da IC\\\\Teste de Rotação\\\\Com rotacao\\\\{identificador}'\n",
    "    image = rotaciona(image,img_size)\n",
    "    \n",
    "    image.save(rotaciona_path+\".png\")\n",
    "\n",
    "#Guardando as imagens não rotacionadas    \n",
    "for index, image in enumerate(Nao_Rotaciona):\n",
    "    identificador=image[0:13]\n",
    "    nao_rotaciona_path= f'C:\\\\Users\\\\Alyfe Renan Gomes\\\\Programação\\\\Código da IC\\\\Teste de Rotação\\\\Sem rotacao\\\\{identificador}'\n",
    "    \n",
    "    im2 = Image.open(image).convert('L')\n",
    "    im2 = im2.resize((img_size,img_size))\n",
    "    \n",
    "    im2.save(nao_rotaciona_path+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb7946",
   "metadata": {},
   "source": [
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b7f22",
   "metadata": {},
   "source": [
    "# Pegando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920b2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir2 = 'C:\\\\Users\\\\Alyfe Renan Gomes\\\\Programação\\\\Código da IC\\\\Teste de Rotação'\n",
    "data_dir2 = pathlib.Path(data_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb1eb0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323 324\n"
     ]
    }
   ],
   "source": [
    "#Definindo função útil\n",
    "def get_images(Rot_path,SemRot_path):\n",
    "    \"Função que retorna duas listas: uma com as imagens rotacionadas e a outra com imagens sem rotação\"\n",
    "    \n",
    "    Rot_images= list(filter(lambda x: True if x.endswith('png') else False,os.listdir(Rot_path)))\n",
    "    NRot_images = list(filter(lambda x: True if x.endswith('png') else False,os.listdir(SemRot_path)))\n",
    "    \n",
    "    return Rot_images, NRot_images\n",
    "\n",
    "#=====================================================================================================================#\n",
    "\n",
    "#Caso desejado utilizar a função, modifique para o path no qual as imagens estão.\n",
    "Rot_path=r'C:\\\\Users\\\\Alyfe Renan Gomes\\\\Programação\\\\Código da IC\\\\Teste de Rotação\\\\Com rotacao'\n",
    "SemRot_path=r'C:\\\\Users\\\\Alyfe Renan Gomes\\\\Programação\\\\Código da IC\\\\Teste de Rotação\\\\Sem rotacao'\n",
    "\n",
    "Rot1, Sem_Rot1 = get_images(Rot_path,SemRot_path)\n",
    "\n",
    "\n",
    "print(len(Sem_Rot1), len(Rot1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1417eaf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alyfe Renan Gomes\\Programação\\Código da IC\\Teste de Rotação\\Sem rotacao\\CHNCXR_0001_0.png\n",
      "C:\\Users\\Alyfe Renan Gomes\\Programação\\Código da IC\\Teste de Rotação\\Com rotacao\\0002_0.png\n"
     ]
    }
   ],
   "source": [
    "Sem_Rot = list(data_dir2.glob('Sem rotacao/*'))\n",
    "print(Sem_Rot[0])\n",
    "\n",
    "Rot = list(data_dir2.glob('Com rotacao/*'))\n",
    "print(Rot[0])\n",
    "\n",
    "#PIL.Image.open(str(cxr[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694032b",
   "metadata": {},
   "source": [
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f3a3e",
   "metadata": {},
   "source": [
    "# Definindo dados de teste e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa60ff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 647 files belonging to 2 classes.\n",
      "Using 583 files for training.\n"
     ]
    }
   ],
   "source": [
    "#Separando os dados para teste\n",
    "IMG_SIZE=180\n",
    "batch_size=25\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir2,\n",
    "  label_mode='categorical', \n",
    "  validation_split=0.1,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_SIZE, IMG_SIZE),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c138700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 647 files belonging to 2 classes.\n",
      "Using 64 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#Separando os dados para validação\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir2,\n",
    "  validation_split=0.1,\n",
    "  label_mode='categorical', \n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(IMG_SIZE, IMG_SIZE),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db124703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Com rotacao', 'Sem rotacao']\n"
     ]
    }
   ],
   "source": [
    "#Identificando as classes\n",
    "class_names=train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aade260f",
   "metadata": {},
   "source": [
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cdca21",
   "metadata": {},
   "source": [
    "# Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab306fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função útil\n",
    "def get_model(IMG_SIZE):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    base_model =applications.ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "    \n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(learning_rate=1e-4, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d71ddb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 6, 6, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 73728)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                737290    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,325,024\n",
      "Trainable params: 737,312\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 69s 3s/step - loss: 0.4785 - accuracy: 0.7822 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 62s 3s/step - loss: 0.1493 - accuracy: 0.9280 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 51s 2s/step - loss: 0.1604 - accuracy: 0.9383 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 52s 2s/step - loss: 0.1330 - accuracy: 0.9571 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 57s 2s/step - loss: 0.1064 - accuracy: 0.9726 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 55s 2s/step - loss: 0.1398 - accuracy: 0.9468 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 56s 2s/step - loss: 0.1101 - accuracy: 0.9743 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 56s 2s/step - loss: 0.1198 - accuracy: 0.9588 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 58s 2s/step - loss: 0.1032 - accuracy: 0.9674 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 57s 2s/step - loss: 0.1220 - accuracy: 0.9691 - val_loss: 0.0019 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "resnet_model = get_model(IMG_SIZE)\n",
    "\n",
    "resnet_model.summary()  #Visualizando o que foi criado\n",
    "\n",
    "#=====================================================================================================================#\n",
    "\n",
    "#Realizando o treinamento\n",
    "epochs=10\n",
    "history = resnet_model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9343d9f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Avaliando o modelo\n",
    "fig1 = plt.gcf()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.axis(ymin=0.4,ymax=1)\n",
    "plt.grid()\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876366c",
   "metadata": {},
   "source": [
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60c5b0",
   "metadata": {},
   "source": [
    "# Fazendo previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e750701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image=cv2.imread('CHNCXR_0501_1.png')\n",
    "#[CHNCXR_0083_0,CHNCXR_0145_0,CHNCXR_0131_0 -> CHNCXR_0122_0] / [CHNCXR_0625_1,CHNCXR_0609_1,CHNCXR_0568_1 -> CHNCXR_0644_1]\n",
    "image_resized= cv2.resize(image, (IMG_SIZE,IMG_SIZE))\n",
    "image=np.expand_dims(image_resized,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d2acdf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.002379e-07 9.999995e-01]]\n"
     ]
    }
   ],
   "source": [
    "pred=resnet_model.predict(image)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f68b0db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição:  Sem rotacao\n"
     ]
    }
   ],
   "source": [
    "output_class=class_names[np.argmax(pred)]\n",
    "print(\"Predição: \", output_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abfc6e1",
   "metadata": {},
   "source": [
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f38585",
   "metadata": {},
   "source": [
    "# Aplicando Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac3fb63",
   "metadata": {},
   "source": [
    "### Gerando um dataframe com as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b4e8e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323 324\n"
     ]
    }
   ],
   "source": [
    "#Definindo meu path\n",
    "images_path=r'C:\\\\Users\\\\Alyfe Renan Gomes\\\\Programação\\\\Código da IC\\\\Teste de Rotação\\\\Sem rotacao'\n",
    "Sem_Rot1 = list(filter(lambda x: True if x.endswith('png') else False,os.listdir(images_path)))\n",
    "\n",
    "images_path2=r'C:\\\\Users\\\\Alyfe Renan Gomes\\\\Programação\\\\Código da IC\\\\Teste de Rotação\\\\Com rotacao'\n",
    "Rot1 = list(filter(lambda x: True if x.endswith('png') else False,os.listdir(images_path2)))\n",
    "\n",
    "print(len(Sem_Rot1),len(Rot1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46fe677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construindo as linhas e colunas do meu dataframe\n",
    "auxiliar1=Sem_Rot1\n",
    "for image in Rot1:\n",
    "    auxiliar1.append(image)\n",
    "\n",
    "auxiliar2=[\"Sem rotacao\"]*323\n",
    "\n",
    "for i in [\"Com rotacao\"]*324:\n",
    "    auxiliar2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af81aa66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Nao_Rotaciona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2e8c48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647 647\n"
     ]
    }
   ],
   "source": [
    "print(len(auxiliar1),len(auxiliar2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dad0cea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHNCXR_0001_0.png</td>\n",
       "      <td>Sem rotacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHNCXR_0004_0.png</td>\n",
       "      <td>Sem rotacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHNCXR_0005_0.png</td>\n",
       "      <td>Sem rotacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHNCXR_0008_0.png</td>\n",
       "      <td>Sem rotacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHNCXR_0009_0.png</td>\n",
       "      <td>Sem rotacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0653_1.png</td>\n",
       "      <td>Com rotacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>0655_1.png</td>\n",
       "      <td>Com rotacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0657_1.png</td>\n",
       "      <td>Com rotacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0660_1.png</td>\n",
       "      <td>Com rotacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0661_1.png</td>\n",
       "      <td>Com rotacao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Image        Class\n",
       "0    CHNCXR_0001_0.png  Sem rotacao\n",
       "1    CHNCXR_0004_0.png  Sem rotacao\n",
       "2    CHNCXR_0005_0.png  Sem rotacao\n",
       "3    CHNCXR_0008_0.png  Sem rotacao\n",
       "4    CHNCXR_0009_0.png  Sem rotacao\n",
       "..                 ...          ...\n",
       "642         0653_1.png  Com rotacao\n",
       "643         0655_1.png  Com rotacao\n",
       "644         0657_1.png  Com rotacao\n",
       "645         0660_1.png  Com rotacao\n",
       "646         0661_1.png  Com rotacao\n",
       "\n",
       "[647 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando o dataframe com as imagens relacionando elas com as suas respectivas classes\n",
    "df=pd.DataFrame()\n",
    "df['Image']=list(auxiliar1)\n",
    "df['Class']=list(auxiliar2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82e440cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train.csv', index = False)\n",
    "train=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4e5045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iremos dividir o dataset\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333f5d0",
   "metadata": {},
   "source": [
    "### Pegando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "073736b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'C:\\\\Users\\\\Alyfe Renan Gomes\\\\Programação\\\\Código da IC\\\\Teste de Rotação\\\\Train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79a629",
   "metadata": {},
   "source": [
    "### Preparando os Kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5737ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardando a média de todas as predições\n",
    "\n",
    "main_pred = []\n",
    "error = []\n",
    "data_kfold = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "197cc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando X,Y para treino\n",
    "\n",
    "train_y = df.Class\n",
    "train_x = df.drop(['Class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c7752b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 180\n",
    "BATCH_SIZE = 25\n",
    "EPOCHS = 10\n",
    "N_SPLIT = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0387fa",
   "metadata": {},
   "source": [
    "### Treino e predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45c74513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 582 validated image filenames belonging to 2 classes.\n",
      "Found 65 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 36s 1s/step - loss: 0.5720 - accuracy: 0.8312 - val_loss: 3.4277e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1422 - accuracy: 0.9210 - val_loss: 1.4598e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1372 - accuracy: 0.9497 - val_loss: 1.3757e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1165 - accuracy: 0.9336 - val_loss: 1.0421e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0999 - accuracy: 0.9497 - val_loss: 9.2065e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1249 - accuracy: 0.9515 - val_loss: 7.8078e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1282 - accuracy: 0.9533 - val_loss: 6.7789e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 34s 1s/step - loss: 0.1127 - accuracy: 0.9551 - val_loss: 6.9490e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.1212 - accuracy: 0.9443 - val_loss: 6.0059e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 34s 1s/step - loss: 0.1145 - accuracy: 0.9479 - val_loss: 1.3839e-05 - val_accuracy: 1.0000\n",
      "Found 647 validated image filenames.\n",
      "Found 582 validated image filenames belonging to 2 classes.\n",
      "Found 65 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 36s 1s/step - loss: 0.5288 - accuracy: 0.7217 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1583 - accuracy: 0.9497 - val_loss: 6.3728e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1305 - accuracy: 0.9461 - val_loss: 2.6657e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.1249 - accuracy: 0.9569 - val_loss: 3.5607e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 36s 2s/step - loss: 0.1120 - accuracy: 0.9652 - val_loss: 1.1647e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.1174 - accuracy: 0.9587 - val_loss: 2.0834e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1095 - accuracy: 0.9605 - val_loss: 1.2316e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 35s 2s/step - loss: 0.0710 - accuracy: 0.9731 - val_loss: 5.1259e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.0792 - accuracy: 0.9551 - val_loss: 3.4002e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.0904 - accuracy: 0.9605 - val_loss: 2.5932e-06 - val_accuracy: 1.0000\n",
      "Found 647 validated image filenames.\n",
      "Found 582 validated image filenames belonging to 2 classes.\n",
      "Found 65 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 35s 1s/step - loss: 0.4194 - accuracy: 0.8205 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0901 - accuracy: 0.9749 - val_loss: 1.9218e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.0708 - accuracy: 0.9695 - val_loss: 4.8146e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.0717 - accuracy: 0.9785 - val_loss: 6.6051e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.0567 - accuracy: 0.9838 - val_loss: 2.2622e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 34s 1s/step - loss: 0.0448 - accuracy: 0.9856 - val_loss: 1.3243e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.0474 - accuracy: 0.9856 - val_loss: 1.1052e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.0576 - accuracy: 0.9820 - val_loss: 7.9021e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 34s 1s/step - loss: 0.0509 - accuracy: 0.9820 - val_loss: 6.2518e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.0502 - accuracy: 0.9838 - val_loss: 1.9166e-05 - val_accuracy: 1.0000\n",
      "Found 647 validated image filenames.\n",
      "Found 582 validated image filenames belonging to 2 classes.\n",
      "Found 65 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 40s 2s/step - loss: 0.7287 - accuracy: 0.6212 - val_loss: 0.1907 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 36s 2s/step - loss: 0.3415 - accuracy: 0.8492 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 36s 2s/step - loss: 0.2966 - accuracy: 0.8492 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.2977 - accuracy: 0.8671 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.2921 - accuracy: 0.8330 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.2949 - accuracy: 0.8600 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.2966 - accuracy: 0.8366 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.2796 - accuracy: 0.8528 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.2479 - accuracy: 0.8797 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.2528 - accuracy: 0.8851 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Found 647 validated image filenames.\n",
      "Found 582 validated image filenames belonging to 2 classes.\n",
      "Found 65 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 35s 1s/step - loss: 0.3697 - accuracy: 0.8474 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1040 - accuracy: 0.9569 - val_loss: 8.7492e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0549 - accuracy: 0.9713 - val_loss: 5.5518e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0443 - accuracy: 0.9803 - val_loss: 3.2743e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0536 - accuracy: 0.9767 - val_loss: 2.5625e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0518 - accuracy: 0.9785 - val_loss: 2.8770e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0397 - accuracy: 0.9731 - val_loss: 2.8822e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0576 - accuracy: 0.9695 - val_loss: 4.2005e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0392 - accuracy: 0.9803 - val_loss: 3.7272e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0365 - accuracy: 0.9749 - val_loss: 2.9585e-05 - val_accuracy: 1.0000\n",
      "Found 647 validated image filenames.\n",
      "Found 582 validated image filenames belonging to 2 classes.\n",
      "Found 65 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 35s 1s/step - loss: 0.5913 - accuracy: 0.8115 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 32s 1s/step - loss: 0.1815 - accuracy: 0.9354 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0824 - accuracy: 0.9731 - val_loss: 5.6628e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0958 - accuracy: 0.9731 - val_loss: 4.1585e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0681 - accuracy: 0.9767 - val_loss: 3.3743e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0694 - accuracy: 0.9803 - val_loss: 2.8695e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0821 - accuracy: 0.9713 - val_loss: 1.7557e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0634 - accuracy: 0.9767 - val_loss: 1.1526e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0528 - accuracy: 0.9892 - val_loss: 7.6979e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0809 - accuracy: 0.9803 - val_loss: 5.8579e-05 - val_accuracy: 1.0000\n",
      "Found 647 validated image filenames.\n",
      "Found 582 validated image filenames belonging to 2 classes.\n",
      "Found 65 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 35s 1s/step - loss: 0.4907 - accuracy: 0.8043 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1407 - accuracy: 0.9479 - val_loss: 9.8016e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1177 - accuracy: 0.9713 - val_loss: 2.3673e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1309 - accuracy: 0.9605 - val_loss: 7.2739e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.1012 - accuracy: 0.9856 - val_loss: 1.4511e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1167 - accuracy: 0.9731 - val_loss: 1.1383e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0969 - accuracy: 0.9803 - val_loss: 2.1748e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1059 - accuracy: 0.9910 - val_loss: 1.2422e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0972 - accuracy: 0.9874 - val_loss: 1.2352e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0946 - accuracy: 0.9856 - val_loss: 5.7909e-06 - val_accuracy: 1.0000\n",
      "Found 647 validated image filenames.\n",
      "Found 583 validated image filenames belonging to 2 classes.\n",
      "Found 64 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 35s 1s/step - loss: 0.4787 - accuracy: 0.7867 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1357 - accuracy: 0.8853 - val_loss: 6.1926e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1177 - accuracy: 0.9229 - val_loss: 3.3577e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0986 - accuracy: 0.9677 - val_loss: 4.4223e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1117 - accuracy: 0.9857 - val_loss: 1.6887e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0963 - accuracy: 0.9821 - val_loss: 8.1599e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0988 - accuracy: 0.9892 - val_loss: 2.7492e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0889 - accuracy: 0.9857 - val_loss: 3.1552e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0951 - accuracy: 0.9928 - val_loss: 4.6769e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.1057 - accuracy: 0.9896 - val_loss: 1.6633e-06 - val_accuracy: 1.0000\n",
      "Found 647 validated image filenames.\n",
      "Found 583 validated image filenames belonging to 2 classes.\n",
      "Found 64 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 35s 1s/step - loss: 0.6289 - accuracy: 0.6918 - val_loss: 0.0565 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.2279 - accuracy: 0.8978 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1581 - accuracy: 0.9229 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1283 - accuracy: 0.9319 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 33s 1s/step - loss: 0.1240 - accuracy: 0.9462 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0974 - accuracy: 0.9534 - val_loss: 7.9670e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1078 - accuracy: 0.9265 - val_loss: 2.1314e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0742 - accuracy: 0.9552 - val_loss: 9.1944e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0628 - accuracy: 0.9749 - val_loss: 2.2321e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.0603 - accuracy: 0.9659 - val_loss: 1.2546e-05 - val_accuracy: 1.0000\n",
      "Found 647 validated image filenames.\n",
      "Found 583 validated image filenames belonging to 2 classes.\n",
      "Found 64 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 35s 1s/step - loss: 0.5443 - accuracy: 0.7276 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.2574 - accuracy: 0.8530 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1821 - accuracy: 0.8728 - val_loss: 6.7039e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1482 - accuracy: 0.9194 - val_loss: 4.8248e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1221 - accuracy: 0.9301 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1272 - accuracy: 0.9373 - val_loss: 9.7695e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1527 - accuracy: 0.9229 - val_loss: 4.1725e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1341 - accuracy: 0.9373 - val_loss: 1.8136e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1255 - accuracy: 0.9588 - val_loss: 1.3892e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 32s 1s/step - loss: 0.1112 - accuracy: 0.9677 - val_loss: 1.0862e-04 - val_accuracy: 1.0000\n",
      "Found 647 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#Iniciando Data Generators\n",
    "train_datagen = ImageDataGenerator(shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "#=====================================================================================================================#\n",
    "\n",
    "# k-fold\n",
    "kfold = StratifiedKFold(n_splits=N_SPLIT,shuffle=True,random_state=42)\n",
    "\n",
    "# Variable for keeping count of split we are executing\n",
    "j = 0\n",
    "\n",
    "# K-fold Train and test for each split\n",
    "for train_idx, val_idx in list(kfold.split(train_x,train_y)):\n",
    "    x_train_df = df.iloc[train_idx]\n",
    "    x_valid_df = df.iloc[val_idx]\n",
    "    j+=1\n",
    "    \n",
    "    training_set = train_datagen.flow_from_dataframe(dataframe=x_train_df, directory=TRAIN_PATH,\n",
    "                                                 x_col=\"Image\", y_col=\"Class\",\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "    \n",
    "    validation_set = validation_datagen.flow_from_dataframe(dataframe=x_valid_df, directory=TRAIN_PATH,\n",
    "                                                 x_col=\"Image\", y_col=\"Class\",\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model_test = get_model(IMG_SIZE)\n",
    "    \n",
    "    \n",
    "    history = model_test.fit( training_set,\n",
    "                                        validation_data=validation_set,\n",
    "                                        epochs = EPOCHS,\n",
    "                                        steps_per_epoch=x_train_df.shape[0] // BATCH_SIZE\n",
    "                                        )\n",
    "    \n",
    "    test_generator = ImageDataGenerator()\n",
    "    \n",
    "    test_set = test_generator.flow_from_dataframe(dataframe=train, directory=TRAIN_PATH,\n",
    "                                                 x_col=\"Image\",y_col=None,\n",
    "                                                 class_mode=None,\n",
    "                                                 target_size=(IMG_SIZE,IMG_SIZE))\n",
    "    \n",
    "    #=====================================================================================================================#\n",
    "    \n",
    "    pred= model_test.predict(test_set, len(train) // BATCH_SIZE)\n",
    "    predicted_class_indices=np.argmax(pred,axis=1)\n",
    "                                       \n",
    "    data_kfold[j] = predicted_class_indices\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81dfb8",
   "metadata": {},
   "source": [
    "# ============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2a1430b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1   2   3   4   5   6   7   8   9   10\n",
       "0     0   1   1   1   0   0   0   0   1   1\n",
       "1     1   1   1   1   0   1   0   0   1   1\n",
       "2     0   1   1   0   1   1   0   1   1   0\n",
       "3     0   1   0   0   1   0   0   1   0   1\n",
       "4     1   1   1   0   0   1   1   1   0   0\n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "642   0   1   0   1   0   1   1   0   0   0\n",
       "643   1   1   0   1   1   0   1   0   0   1\n",
       "644   1   0   0   1   0   0   0   1   1   1\n",
       "645   1   1   0   1   1   1   1   0   0   0\n",
       "646   1   0   1   1   1   0   1   1   0   0\n",
       "\n",
       "[647 rows x 10 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# holder\n",
    "data_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e0c4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on single iteration of HoldOut\n",
    "predicted_class_indices = data_kfold[1]\n",
    "labels=(training_set.class_indices)\n",
    "labels2=dict((v,k) for k,v in labels.items())\n",
    "predictions=[labels2[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f27da771",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fecc849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking The Label with Maximum Occurences\n",
    "\n",
    "labels=(training_set.class_indices)\n",
    "labels2=dict((v,k) for k,v in labels.items())\n",
    "import collections \n",
    "for i in range(len(data_kfold)):\n",
    "    co = collections.Counter(data_kfold.loc[i])\n",
    "    co = sorted(co.items(),key=lambda x: x[1],reverse=True)\n",
    "    ans.Class.loc[i] = labels2[co[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48f920da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-Fold Method:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Averaged K-Fold Output\n",
    "print(\"Accuracy of K-Fold Method: \", round(accuracy_score(train.Class,ans.Class),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
